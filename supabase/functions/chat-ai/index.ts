
import { serve } from 'https://deno.land/std@0.168.0/http/server.ts';
import { buildSystemPrompt, buildLearningPrompt } from './prompts.ts';
import { getDoctorProfile, updateDoctorLearning, saveFeedback } from './learning.ts';
import { buildReferenceContext } from './formula-reference.ts';
import { processAutoLearning } from './auto-learning.ts';

const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Headers': 'authorization, x-client-info, apikey, content-type',
};

serve(async (req) => {
  if (req.method === 'OPTIONS') {
    return new Response('ok', { headers: corsHeaders });
  }

  const startTime = performance.now();

  try {
    console.log('üöÄ Processando requisi√ß√£o de chat-ai...');
    
    const { 
      message, 
      specialty = 'geral', 
      customActives = [], 
      userId,
      feedback,
      originalAnalysis,
      rating
    } = await req.json();

    // Se √© feedback, processar aprendizado
    if (feedback && originalAnalysis && userId) {
      console.log('üìö Processando feedback para aprendizado...');
      
      await saveFeedback(userId, originalAnalysis, feedback, rating || 5);
      
      const learningPrompt = buildLearningPrompt(userId, feedback, originalAnalysis);
      
      const openaiResponse = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${Deno.env.get('OPENAI_API_KEY')}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: 'gpt-4o-mini',
          messages: [
            { role: 'user', content: learningPrompt }
          ],
          max_tokens: 1000,
          temperature: 0.3,
        }),
      });

      if (openaiResponse.ok) {
        const learningResult = await openaiResponse.json();
        const learningData = learningResult.choices[0]?.message?.content;
        
        try {
          const parsedLearning = JSON.parse(learningData);
          await updateDoctorLearning(userId, parsedLearning);
          console.log('‚úÖ Aprendizado processado e salvo');
        } catch (e) {
          console.log('‚ùå Erro ao parsear dados de aprendizado:', e);
        }
      }

      return new Response(
        JSON.stringify({ success: true, message: 'Feedback processado com sucesso!' }),
        { headers: { ...corsHeaders, 'Content-Type': 'application/json' } }
      );
    }

    if (!message) {
      throw new Error('Mensagem √© obrigat√≥ria');
    }

    console.log('üîß Preparando mensagens com especialidade:', specialty);

    // Buscar perfil do m√©dico se userId fornecido
    let doctorProfile = null;
    if (userId) {
      doctorProfile = await getDoctorProfile(userId);
      console.log('üë®‚Äç‚öïÔ∏è Perfil do m√©dico carregado:', doctorProfile?.specialty || 'Sem perfil');
    }

    // Construir prompt do sistema com contexto de refer√™ncia
    const systemPrompt = await buildSystemPrompt(customActives, doctorProfile, specialty, message);

    const messages = [
      {
        role: 'system',
        content: systemPrompt
      },
      {
        role: 'user',
        content: message
      }
    ];

    console.log('ü§ñ Enviando para OpenAI...');

    const openaiApiKey = Deno.env.get('OPENAI_API_KEY');
    if (!openaiApiKey) {
      throw new Error('OPENAI_API_KEY n√£o configurada');
    }

    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${openaiApiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'gpt-4o',
        messages: messages,
        max_tokens: 4000,
        temperature: 0.7,
      }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error('‚ùå Erro da OpenAI API:', response.status, errorText);
      throw new Error(`OpenAI API error: ${response.status} - ${errorText}`);
    }

    const data = await response.json();
    console.log('‚úÖ Resposta da OpenAI recebida');

    const aiResponse = data.choices[0]?.message?.content || 'Desculpe, n√£o foi poss√≠vel gerar uma resposta.';
    const tokensUsed = data.usage?.total_tokens || 0;

    // Processar aprendizado autom√°tico baseado na intera√ß√£o
    if (userId) {
      console.log('üß† Iniciando aprendizado autom√°tico...');
      await processAutoLearning(userId, message, aiResponse, specialty);
    }

    const endTime = performance.now();
    const processingTime = endTime - startTime;

    console.log(`‚ö° An√°lise conclu√≠da em ${processingTime.toFixed(2)}ms`);

    return new Response(
      JSON.stringify({ 
        response: aiResponse,
        model: 'gpt-4o',
        hasReferenceContext: true,
        tokens: tokensUsed,
        processingTime: processingTime
      }),
      { 
        headers: { 
          ...corsHeaders, 
          'Content-Type': 'application/json' 
        } 
      }
    );

  } catch (error) {
    const endTime = performance.now();
    const processingTime = endTime - startTime;
    
    console.error('‚ùå Erro na fun√ß√£o:', error);
    
    return new Response(
      JSON.stringify({ 
        error: error.message || 'Erro interno do servidor',
        details: error.toString(),
        processingTime: processingTime
      }),
      { 
        status: 500, 
        headers: { 
          ...corsHeaders, 
          'Content-Type': 'application/json' 
        } 
      }
    );
  }
});
